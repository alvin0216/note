import{_ as t,o as e,c as l,Q as a}from"./chunks/framework.20999013.js";const _=JSON.parse('{"title":"AI","description":"","frontmatter":{"title":"AI","date":"2025-12-15T12:32:19.000Z","sidebar":"auto","tags":["AI"],"categories":["AI"]},"headers":[],"relativePath":"ai/index.md","lastUpdated":1765769129000}'),s={name:"ai/index.md"},n=a('<h3 id="awesome" tabindex="-1">Awesome <a class="header-anchor" href="#awesome" aria-label="Permalink to &quot;Awesome&quot;">​</a></h3><p><a href="https://mmh1.top/#/ai-tutorial" target="_blank" rel="noreferrer">https://mmh1.top/#/ai-tutorial</a></p><p>理解模型的核心概念确实是实践前的重要一步。下面我用一个表格来清晰解释你提到的这几个关键术语。</p><h3 id="📖-核心概念解析" tabindex="-1">📖 核心概念解析 <a class="header-anchor" href="#📖-核心概念解析" aria-label="Permalink to &quot;📖 核心概念解析&quot;">​</a></h3><table><thead><tr><th style="text-align:left;">概念</th><th style="text-align:left;">核心定义</th><th style="text-align:left;">类比解释</th><th style="text-align:left;">关键原因/意义</th><th style="text-align:left;">关联实践</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>大模型 (LLM)</strong></td><td style="text-align:left;">参数量巨大（通常数十亿以上）、基于海量数据训练、能处理多种复杂任务的自然语言处理模型。</td><td style="text-align:left;">像一个<strong>博览群书的超级学者</strong>，通识能力极强，能回答广泛问题、写作、编程等。</td><td style="text-align:left;">其涌现能力（未经专门训练就能完成新任务）是 AI 发展的突破，成为当前 AI 应用的基础。</td><td style="text-align:left;">直接使用（提问/对话），或作为基座模型进行<strong>微调</strong>。</td></tr><tr><td style="text-align:left;"><strong>微调 (Fine-tuning)</strong></td><td style="text-align:left;">在预训练好的<strong>大模型</strong>基础上，用特定领域的小规模数据继续训练，使其适应专门任务。</td><td style="text-align:left;">让“超级学者”<strong>攻读一个专业学位</strong>（如法律、医疗），成为该领域的专家。</td><td style="text-align:left;">以较低成本让通用模型获得专业能力，是定制化 AI 应用的主要方法。</td><td style="text-align:left;">需要准备领域数据，使用框架（如 PyTorch）或平台（如 Hugging Face）进行。</td></tr><tr><td style="text-align:left;"><strong>过拟合 (Overfitting)</strong></td><td style="text-align:left;">模型在训练数据上表现完美，但在未见过的测试数据上表现很差，即“<strong>学得太死，不会举一反三</strong>”。</td><td style="text-align:left;">学生<strong>死记硬背了所有习题答案</strong>，但考题稍一变化就不会做。</td><td style="text-align:left;">是模型训练中的核心挑战，衡量模型是否真正学会了“规律”而非“记忆”。</td><td style="text-align:left;">通过划分训练/验证集、早停、正则化、数据增强等技术来避免。</td></tr><tr><td style="text-align:left;"><strong>Transformer</strong></td><td style="text-align:left;">一种基于<strong>自注意力机制</strong>的神经网络架构，是现代<strong>大模型</strong>（如 GPT、BERT）的<strong>核心引擎</strong>。</td><td style="text-align:left;">像一个<strong>超级高效的阅读理解系统</strong>，能同时权衡句子中所有词之间的关系，捕捉长远依赖。</td><td style="text-align:left;">解决了传统模型（如 RNN）处理长文本的瓶颈，并行计算效率高，成为大模型的基石。</td><td style="text-align:left;">理解其结构是深入 NLP 的关键；实际中我们直接调用基于它构建的模型（如 GPT）。</td></tr></tbody></table>',5),r=[n];function o(d,g,i,f,h,x){return e(),l("div",null,r)}const c=t(s,[["render",o]]);export{_ as __pageData,c as default};

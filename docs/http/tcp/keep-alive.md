---
title: keep-alive
---

HTTP 的请求是建立在 TCP 的连接上面的进行发送的，TCP 的连接又分为长连接和短连接。

HTTP 发送的时候要先创建 TCP 的连接，HTTP 发送并且接收完返回，因为 HTTP 请求已经结束了，浏览器和服务端就会商量要不要关闭 TCP 连接。

如果不关闭，TCP 连接开着会有一定的消耗，如果接下去还有请求，可以在这个 TCP 上进行发送，不用再通过三次握手建立连接。

如果关闭了，下次的 HTTP 请求要重新创建 TCP 连接，这时候又会有网络延时的开销。

## 长连接

`HTTP1.1` 连接默认是长连接，

在客户端，可以在请求头里加上“`Connection: close`”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。

服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 `Nginx` 来举例，它有两种方式：

1. 使用“`keepalive_timeout`”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。
2. 使用“`keepalive_requests`”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。

## HTTP 队头阻塞

“队头阻塞”与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。

HTTP 请求是有先后顺序的，报文必须是一发一收， 里面的任务被放在一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理。这就是著名的**HTTP 队头阻塞**问题

### 并发连接

因为“请求 - 应答”模型不能变，所以“队头阻塞”问题在 `HTTP/1.1` 里无法解决，只能缓解，有什么办法呢？

这在 HTTP 里就是“**并发连接**”（concurrent connections），也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。

对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务。

`Chrome` 上一个域名最多可以并发 6 个长连接，比如我有 10 个连接，那么 Chrome 会先并发 6 个连接，等完成一个后才慢慢加载后面的 4 个连接。

但其实，即使是提高了并发连接，还是不能满足人们对性能的需求。

### 域名分片

一个域名不是可以并发 6 个长连接吗？那我就多分几个域名。

text.baidu.com、img.baidu.com

这样一个 `baidu.com`域名下可以分出非常多的二级域名，而它们都指向同样的一台服务器，能够并发的长连接数更多了，事实上也更好地解决了队头阻塞的问题。

:::danger

http1.1 还是没解决队头阻塞，一个 TCP 最多可以有一个 HTTP 请求，一个浏览器例如 chrome 对一个站点可以同时保持 6 个 TCP 连接，后面的还是得排队。

:::
